{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    "---\n",
    "- [File Input](#input)\n",
    "- [Delimiters](#delimiters)\n",
    "- [CSV files](#csv)\n",
    "- [Files in other locations](#locations)\n",
    "- [File Output](#output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Input\n",
    "---\n",
    "<a class=\"anchor\" id=\"input\"></a>\n",
    "So far, we have just taken in short words and sentences from the user. However, in reality we will want to examine much larger sets of text, including word documents, spreadsheets, and web pages.  In order to do this, we need to learn how to tell Python to look through a file.\n",
    "\n",
    "If your Python program is in the same folder that the text file that you would like to read is in, then we just need the open command. Suppose we want to read the lyrics in a file saved as \"kanye.txt\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try the following code, we will get an error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5b2602d4c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kanye.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we'll need to use the .read command. Remember to always put your file name in quotations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "She has no idea what she's doing in college\n",
      "That major that she majored in don't make no money\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "The concept of school seems so secure\n",
      "Sophomore, three years, ain't picked a career\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "'Cause her baby daddy don't really care\n",
      "She's so precious with the peer pressure\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "Then she cut it all off now she look like Eve\n",
      "And she be dealing with some issues that you can't believe\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "That's why you always see me with at least one of my watches\n",
      "Rollies and Pasha's done drove me crazy\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "Just to be like you ain't up on this\n",
      "And I can't even go to the grocery store\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "The people highest up got the lowest self esteem\n",
      "The prettiest people do the ugliest things\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "We trying to buy back our 40 acres\n",
      "And for that paper, look how low we a'stoop\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "Before I had a house and I'd do it again\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "I got a couple past due bills, I won't get specific\n",
      "I got a problem with spending before I get it\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "This grave shift is like a slave ship)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt').read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to read the first 10 lines of the song, we might try typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when i\n"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt').read()\n",
    "print(f[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh, oh, this gives us the first 10 characters, not the first 10 lines. Read is a useful function for manipulating files, in cases when you want to process the entire contents of a file, but it isn't very good when dealing with large files. Instead, we'll iterate over line at a time using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "\n",
      "She has no idea what she's doing in college\n",
      "\n",
      "That major that she majored in don't make no money\n",
      "\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "\n",
      "The concept of school seems so secure\n",
      "\n",
      "Sophomore, three years, ain't picked a career\n",
      "\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "\n",
      "'Cause her baby daddy don't really care\n",
      "\n",
      "She's so precious with the peer pressure\n",
      "\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "\n",
      "Then she cut it all off now she look like Eve\n",
      "\n",
      "And she be dealing with some issues that you can't believe\n",
      "\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "\n",
      "That's why you always see me with at least one of my watches\n",
      "\n",
      "Rollies and Pasha's done drove me crazy\n",
      "\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "\n",
      "Just to be like you ain't up on this\n",
      "\n",
      "And I can't even go to the grocery store\n",
      "\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "\n",
      "The people highest up got the lowest self esteem\n",
      "\n",
      "The prettiest people do the ugliest things\n",
      "\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "\n",
      "We trying to buy back our 40 acres\n",
      "\n",
      "And for that paper, look how low we a'stoop\n",
      "\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "\n",
      "Before I had a house and I'd do it again\n",
      "\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "\n",
      "I got a couple past due bills, I won't get specific\n",
      "\n",
      "I got a problem with spending before I get it\n",
      "\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "\n",
      "This grave shift is like a slave ship)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('kanye.txt'):   \n",
    "   print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of extra spaces between the lyrics. We can use the strip command to delete them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "She has no idea what she's doing in college\n",
      "That major that she majored in don't make no money\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "The concept of school seems so secure\n",
      "Sophomore, three years, ain't picked a career\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "'Cause her baby daddy don't really care\n",
      "She's so precious with the peer pressure\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "Then she cut it all off now she look like Eve\n",
      "And she be dealing with some issues that you can't believe\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "That's why you always see me with at least one of my watches\n",
      "Rollies and Pasha's done drove me crazy\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "Just to be like you ain't up on this\n",
      "And I can't even go to the grocery store\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "The people highest up got the lowest self esteem\n",
      "The prettiest people do the ugliest things\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "We trying to buy back our 40 acres\n",
      "And for that paper, look how low we a'stoop\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "Before I had a house and I'd do it again\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "I got a couple past due bills, I won't get specific\n",
      "I got a problem with spending before I get it\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "This grave shift is like a slave ship)\n"
     ]
    }
   ],
   "source": [
    "for line in open('kanye.txt'):   \n",
    "   print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since opening the \"kanye.txt\" file was successful, the operating system returned us a file handle. The file handle is not the actual data contained in the file, but instead it is a “handle” that we can use to read the data. You are given a handle if the requested file exists and you have the proper permissions to read the file.\n",
    "\n",
    "If the file does not exist, open will fail with a traceback and you will not get a handle to access the contents of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'missingfile.text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6484678794cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missingfile.text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'missingfile.text'"
     ]
    }
   ],
   "source": [
    "f = open('missingfile.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times, the first line of data file contains headers, i.e., labels for the columns. For example, consider this football data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team,Games,Wins,Losses,Draws,Goals,Goals Allowed,Points\n",
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n"
     ]
    }
   ],
   "source": [
    "for line in open('football.txt'):   \n",
    "   print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want to store the header row, we can use \"next\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to store the header for later, you can use readline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n",
      "header: Team,Games,Wins,Losses,Draws,Goals,Goals Allowed,Points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        print(line.strip())\n",
    "    print('header:', header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to count the number of times \"falls\" appears in the lyrics. In this case, we will want to break up each sentence into a list of words using the split command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for line in open('kanye.txt'):   \n",
    "    words = line.strip().split()\n",
    "    if 'falls' in words:\n",
    "        count = count +1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to print out what lines in the file \"falls\" appears on. In that case, we can use the enumerate function. The enumerate function iterates through items in a list and creates an index for them. Let's do an easier example first. Let's say I had a list of colors and I wanted to print the color and its index on a separate line. I would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 red\n",
      "1 blue\n",
      "2 yellow\n",
      "3 blue\n",
      "4 green\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'yellow', 'blue', 'green']\n",
    "for index, color in enumerate(colors):\n",
    "    print(index, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use enumerate to print the lines that \"falls\" is on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falls is on line 0\n",
      "falls is on line 1\n",
      "falls is on line 4\n",
      "falls is on line 5\n",
      "falls is on line 32\n",
      "falls is on line 33\n",
      "falls is on line 60\n",
      "falls is on line 61\n",
      "falls is on line 88\n",
      "falls is on line 89\n",
      "falls is on line 90\n",
      "falls is on line 91\n",
      "falls is on line 92\n",
      "falls is on line 93\n",
      "falls is on line 94\n",
      "falls is on line 95\n",
      "count: 16\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, line in enumerate(open('kanye.txt')):   \n",
    "    words = line.strip().split()\n",
    "    if 'falls' in words:\n",
    "        count = count +1\n",
    "        print('falls is on line', index)\n",
    "print('count:', count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's put everything together. Suppose we want to break up the kanye file into words. We'll make a dictionary of the words and their corresponding frequencies. Then, we'll print out the list of words in decending order of frequency. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 it\n",
      "20 all\n",
      "17 down\n",
      "16 falls\n",
      "16 a\n",
      "16 I\n",
      "10 I'm\n",
      "9 to\n",
      "9 the\n",
      "8 when\n",
      "8 telling\n",
      "8 buy\n",
      "8 and\n",
      "8 all,\n",
      "8 Oh,\n",
      "7 you,\n",
      "6 you\n",
      "6 with\n",
      "6 that\n",
      "6 so\n",
      "6 she\n",
      "6 of\n",
      "6 like\n",
      "5 we\n",
      "5 her\n",
      "5 can't\n",
      "5 'Cause\n",
      "4 they\n",
      "4 self\n",
      "4 ohh,\n",
      "4 oh,\n",
      "4 in\n",
      "4 ain't\n",
      "4 We\n",
      "4 And\n",
      "3 up\n",
      "3 this\n",
      "3 that's\n",
      "3 on\n",
      "3 me\n",
      "3 look\n",
      "3 got\n",
      "3 get\n",
      "3 even\n",
      "3 don't\n",
      "3 do\n",
      "3 be\n",
      "3 The\n",
      "3 She\n",
      "2 won't\n",
      "2 why\n",
      "2 wanna\n",
      "2 us\n",
      "2 thou\n",
      "2 some\n",
      "2 she's\n",
      "2 seems\n",
      "2 really\n",
      "2 promise,\n",
      "2 people\n",
      "2 our\n",
      "2 off\n",
      "2 no\n",
      "2 money\n",
      "2 just\n",
      "2 it,\n",
      "2 how\n",
      "2 hate\n",
      "2 hair\n",
      "2 had\n",
      "2 f\n",
      "2 conscious\n",
      "2 but\n",
      "2 at\n",
      "2 act\n",
      "2 Then\n",
      "2 That's\n",
      "2 But\n",
      "2 'em\n",
      "1 years,\n",
      "1 workin'\n",
      "1 will\n",
      "1 white\n",
      "1 what's\n",
      "1 what\n",
      "1 went\n",
      "1 well\n",
      "1 weave\n",
      "1 wealth\n",
      "1 way\n",
      "1 watches\n",
      "1 us,\n",
      "1 ugliest\n",
      "1 trying\n",
      "1 treat\n",
      "1 three\n",
      "1 things\n",
      "1 than\n",
      "1 terrific\n",
      "1 tell\n",
      "1 team\n",
      "1 store\n",
      "1 still\n",
      "1 stay\n",
      "1 spent\n",
      "1 spending\n",
      "1 specific\n",
      "1 slave\n",
      "1 shorty's\n",
      "1 shirt\n",
      "1 ship)\n",
      "1 shine\n",
      "1 shift\n",
      "1 see\n",
      "1 secure\n",
      "1 screw\n",
      "1 school\n",
      "1 say\n",
      "1 road\n",
      "1 rings\n",
      "1 riches\n",
      "1 retail\n",
      "1 pushing\n",
      "1 pronounce\n",
      "1 problem\n",
      "1 prettiest\n",
      "1 pressure\n",
      "1 precious\n",
      "1 police,\n",
      "1 picked\n",
      "1 peer\n",
      "1 past\n",
      "1 pass\n",
      "1 parents\n",
      "1 paper,\n",
      "1 pairs\n",
      "1 paid\n",
      "1 out,\n",
      "1 out\n",
      "1 ourself\n",
      "1 ones\n",
      "1 one\n",
      "1 now\n",
      "1 nothing,\n",
      "1 new\n",
      "1 need\n",
      "1 named\n",
      "1 my\n",
      "1 man\n",
      "1 make\n",
      "1 majored\n",
      "1 major\n",
      "1 made\n",
      "1 lowest\n",
      "1 low\n",
      "1 love\n",
      "1 lot\n",
      "1 looked\n",
      "1 long\n",
      "1 living\n",
      "1 like,\n",
      "1 least\n",
      "1 keep\n",
      "1 jail,\n",
      "1 it's\n",
      "1 issues\n",
      "1 is\n",
      "1 inside\n",
      "1 insecure\n",
      "1 if\n",
      "1 idea\n",
      "1 house\n",
      "1 hollering,\n",
      "1 holier\n",
      "1 highest\n",
      "1 here\n",
      "1 has\n",
      "1 grocery\n",
      "1 grave\n",
      "1 gon'\n",
      "1 go\n",
      "1 funny\n",
      "1 freedom\n",
      "1 for\n",
      "1 floss\n",
      "1 first\n",
      "1 few\n",
      "1 female,\n",
      "1 esteem\n",
      "1 enough\n",
      "1 due\n",
      "1 drove\n",
      "1 drop\n",
      "1 dream\n",
      "1 done\n",
      "1 doing\n",
      "1 diamond\n",
      "1 degrade\n",
      "1 dealing\n",
      "1 dealer\n",
      "1 daughter\n",
      "1 dat\n",
      "1 daddy\n",
      "1 cut\n",
      "1 crazy\n",
      "1 crackhead\n",
      "1 crack\n",
      "1 cover\n",
      "1 couple\n",
      "1 coop\n",
      "1 conscious,\n",
      "1 concept\n",
      "1 college\n",
      "1 clothes\n",
      "1 clean\n",
      "1 career\n",
      "1 care\n",
      "1 car\n",
      "1 bucks\n",
      "1 brotha\n",
      "1 black\n",
      "1 bills,\n",
      "1 believe\n",
      "1 before\n",
      "1 because\n",
      "1 ballerific\n",
      "1 ballas'\n",
      "1 back\n",
      "1 baby\n",
      "1 at?\"\n",
      "1 always\n",
      "1 airs\n",
      "1 again\n",
      "1 afford\n",
      "1 admit\n",
      "1 addicted\n",
      "1 acres\n",
      "1 a'stoop\n",
      "1 Without\n",
      "1 We'a\n",
      "1 Versace\n",
      "1 This\n",
      "1 Things\n",
      "1 That\n",
      "1 Sophomore,\n",
      "1 Single\n",
      "1 She's\n",
      "1 Rollies\n",
      "1 Pasha's\n",
      "1 Park\n",
      "1 Now,\n",
      "1 Man,\n",
      "1 Man\n",
      "1 Just\n",
      "1 Jordans,\n",
      "1 Jacob\n",
      "1 It\n",
      "1 I'll\n",
      "1 I'd\n",
      "1 For\n",
      "1 Even\n",
      "1 Eve\n",
      "1 Drug\n",
      "1 Couldn't\n",
      "1 Benz,\n",
      "1 Benz\n",
      "1 Before\n",
      "1 American\n",
      "1 Alexus\n",
      "1 400\n",
      "1 40\n",
      "1 25\n",
      "1 106\n",
      "1 (I's\n",
      "1 'cause\n",
      "1 \"Where\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary of words and frequencies:\n",
    "word_dict = {}\n",
    "for line in open('kanye.txt'):\n",
    "    for word in line.split():\n",
    "        if word in word_dict:\n",
    "            word_dict[word] = word_dict[word] + 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "\n",
    "#create a list to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((val,key))\n",
    "\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if had created the list of tuple in the order (key,val) instead of (val,key)? It would have sorted alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 it\n",
      "20 all\n",
      "17 down\n",
      "16 falls\n",
      "16 a\n",
      "16 I\n",
      "10 I'm\n",
      "9 to\n",
      "9 the\n",
      "8 when\n",
      "8 telling\n",
      "8 buy\n",
      "8 and\n",
      "8 all,\n",
      "8 Oh,\n",
      "7 you,\n",
      "6 you\n",
      "6 with\n",
      "6 that\n",
      "6 so\n",
      "6 she\n",
      "6 of\n",
      "6 like\n",
      "5 we\n",
      "5 her\n",
      "5 can't\n",
      "5 'Cause\n",
      "4 they\n",
      "4 self\n",
      "4 ohh,\n",
      "4 oh,\n",
      "4 in\n",
      "4 ain't\n",
      "4 We\n",
      "4 And\n",
      "3 up\n",
      "3 this\n",
      "3 that's\n",
      "3 on\n",
      "3 me\n",
      "3 look\n",
      "3 got\n",
      "3 get\n",
      "3 even\n",
      "3 don't\n",
      "3 do\n",
      "3 be\n",
      "3 The\n",
      "3 She\n",
      "2 won't\n",
      "2 why\n",
      "2 wanna\n",
      "2 us\n",
      "2 thou\n",
      "2 some\n",
      "2 she's\n",
      "2 seems\n",
      "2 really\n",
      "2 promise,\n",
      "2 people\n",
      "2 our\n",
      "2 off\n",
      "2 no\n",
      "2 money\n",
      "2 just\n",
      "2 it,\n",
      "2 how\n",
      "2 hate\n",
      "2 hair\n",
      "2 had\n",
      "2 f\n",
      "2 conscious\n",
      "2 but\n",
      "2 at\n",
      "2 act\n",
      "2 Then\n",
      "2 That's\n",
      "2 But\n",
      "2 'em\n",
      "1 years,\n",
      "1 workin'\n",
      "1 will\n",
      "1 white\n",
      "1 what's\n",
      "1 what\n",
      "1 went\n",
      "1 well\n",
      "1 weave\n",
      "1 wealth\n",
      "1 way\n",
      "1 watches\n",
      "1 us,\n",
      "1 ugliest\n",
      "1 trying\n",
      "1 treat\n",
      "1 three\n",
      "1 things\n",
      "1 than\n",
      "1 terrific\n",
      "1 tell\n",
      "1 team\n",
      "1 store\n",
      "1 still\n",
      "1 stay\n",
      "1 spent\n",
      "1 spending\n",
      "1 specific\n",
      "1 slave\n",
      "1 shorty's\n",
      "1 shirt\n",
      "1 ship)\n",
      "1 shine\n",
      "1 shift\n",
      "1 see\n",
      "1 secure\n",
      "1 screw\n",
      "1 school\n",
      "1 say\n",
      "1 road\n",
      "1 rings\n",
      "1 riches\n",
      "1 retail\n",
      "1 pushing\n",
      "1 pronounce\n",
      "1 problem\n",
      "1 prettiest\n",
      "1 pressure\n",
      "1 precious\n",
      "1 police,\n",
      "1 picked\n",
      "1 peer\n",
      "1 past\n",
      "1 pass\n",
      "1 parents\n",
      "1 paper,\n",
      "1 pairs\n",
      "1 paid\n",
      "1 out,\n",
      "1 out\n",
      "1 ourself\n",
      "1 ones\n",
      "1 one\n",
      "1 now\n",
      "1 nothing,\n",
      "1 new\n",
      "1 need\n",
      "1 named\n",
      "1 my\n",
      "1 man\n",
      "1 make\n",
      "1 majored\n",
      "1 major\n",
      "1 made\n",
      "1 lowest\n",
      "1 low\n",
      "1 love\n",
      "1 lot\n",
      "1 looked\n",
      "1 long\n",
      "1 living\n",
      "1 like,\n",
      "1 least\n",
      "1 keep\n",
      "1 jail,\n",
      "1 it's\n",
      "1 issues\n",
      "1 is\n",
      "1 inside\n",
      "1 insecure\n",
      "1 if\n",
      "1 idea\n",
      "1 house\n",
      "1 hollering,\n",
      "1 holier\n",
      "1 highest\n",
      "1 here\n",
      "1 has\n",
      "1 grocery\n",
      "1 grave\n",
      "1 gon'\n",
      "1 go\n",
      "1 funny\n",
      "1 freedom\n",
      "1 for\n",
      "1 floss\n",
      "1 first\n",
      "1 few\n",
      "1 female,\n",
      "1 esteem\n",
      "1 enough\n",
      "1 due\n",
      "1 drove\n",
      "1 drop\n",
      "1 dream\n",
      "1 done\n",
      "1 doing\n",
      "1 diamond\n",
      "1 degrade\n",
      "1 dealing\n",
      "1 dealer\n",
      "1 daughter\n",
      "1 dat\n",
      "1 daddy\n",
      "1 cut\n",
      "1 crazy\n",
      "1 crackhead\n",
      "1 crack\n",
      "1 cover\n",
      "1 couple\n",
      "1 coop\n",
      "1 conscious,\n",
      "1 concept\n",
      "1 college\n",
      "1 clothes\n",
      "1 clean\n",
      "1 career\n",
      "1 care\n",
      "1 car\n",
      "1 bucks\n",
      "1 brotha\n",
      "1 black\n",
      "1 bills,\n",
      "1 believe\n",
      "1 before\n",
      "1 because\n",
      "1 ballerific\n",
      "1 ballas'\n",
      "1 back\n",
      "1 baby\n",
      "1 at?\"\n",
      "1 always\n",
      "1 airs\n",
      "1 again\n",
      "1 afford\n",
      "1 admit\n",
      "1 addicted\n",
      "1 acres\n",
      "1 a'stoop\n",
      "1 Without\n",
      "1 We'a\n",
      "1 Versace\n",
      "1 This\n",
      "1 Things\n",
      "1 That\n",
      "1 Sophomore,\n",
      "1 Single\n",
      "1 She's\n",
      "1 Rollies\n",
      "1 Pasha's\n",
      "1 Park\n",
      "1 Now,\n",
      "1 Man,\n",
      "1 Man\n",
      "1 Just\n",
      "1 Jordans,\n",
      "1 Jacob\n",
      "1 It\n",
      "1 I'll\n",
      "1 I'd\n",
      "1 For\n",
      "1 Even\n",
      "1 Eve\n",
      "1 Drug\n",
      "1 Couldn't\n",
      "1 Benz,\n",
      "1 Benz\n",
      "1 Before\n",
      "1 American\n",
      "1 Alexus\n",
      "1 400\n",
      "1 40\n",
      "1 25\n",
      "1 106\n",
      "1 (I's\n",
      "1 'cause\n",
      "1 \"Where\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary of words and frequencies:\n",
    "word_dict = {}\n",
    "for line in open('kanye.txt'):\n",
    "    for word in line.split():\n",
    "        if word in word_dict:\n",
    "            word_dict[word] = word_dict[word] + 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "\n",
    "#create a list to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((val,key))\n",
    "\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we had forgotten .split()? It would have counted the frequency of letters instead of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524  \n",
      "238 e\n",
      "189 a\n",
      "179 t\n",
      "177 l\n",
      "168 o\n",
      "142 s\n",
      "131 n\n",
      "131 h\n",
      "129 i\n",
      "100 \n",
      "\n",
      "81 r\n",
      "75 d\n",
      "71 u\n",
      "63 w\n",
      "55 c\n",
      "53 '\n",
      "52 ,\n",
      "49 f\n",
      "44 y\n",
      "40 m\n",
      "39 g\n",
      "36 p\n",
      "30 I\n",
      "27 b\n",
      "21 k\n",
      "13 v\n",
      "10 T\n",
      "8 O\n",
      "7 W\n",
      "6 S\n",
      "6 C\n",
      "6 A\n",
      "5 j\n",
      "5 B\n",
      "4 0\n",
      "3 z\n",
      "3 J\n",
      "2 P\n",
      "2 M\n",
      "2 E\n",
      "2 4\n",
      "2 \"\n",
      "1 x\n",
      "1 V\n",
      "1 R\n",
      "1 N\n",
      "1 F\n",
      "1 D\n",
      "1 ?\n",
      "1 6\n",
      "1 5\n",
      "1 2\n",
      "1 1\n",
      "1 )\n",
      "1 (\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary of words and frequencies:\n",
    "word_dict = {}\n",
    "for line in open('kanye.txt'):\n",
    "    for word in line:\n",
    "        if word in word_dict:\n",
    "            word_dict[word] = word_dict[word] + 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "\n",
    "#create a list to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((val,key))\n",
    "\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance\n",
    "Write a program that reads the file dance.txt. It should print the most frequently used words in the song from least to greatest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance again\n",
    "Print out the words and their counts in alphabetically descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance again again\n",
    "Write a program that prints out the lines that contain the word \"clean\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance again again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Challenge: - kanye\n",
    "Suppose we wanted to create a program that doesn't check whether \"kanye\" is a word in the line but checks whether the letters in that line could form the word \"Kanye.\" For example, the line \"But she won't drop out, her parents will look at her funny\" contains the letters k, a, n, y, and e. Write a program that prints the locations of the lines that form the word \"Kanye.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert kanye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Challenge: - falls\n",
    "Suppose we wanted to create a program that doesn't check whether \"falls\" is a word in the line but checks whether the letters in that line could form the word \"falls.\" For example, the line \"Single black female, addicted to retail and well\" contains the letters f,a,l,l,s. Write a program that prints the locations of the lines that form the word \"falls.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert falls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delimiters\n",
    "---\n",
    "<a class=\"anchor\" id=\"delimiters\"></a>\n",
    "\n",
    "Up until now, we have been mostly breaking up sentences by words using .split() with the parenthesis blank. However, we can choose to break up the sentence by any delimiter we want. Consider, for example, the student.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Doe, 2000, 101 Main St\n",
      "John Doe, 2001, 123 Oak St\n",
      "Ann Ko, 1999, 57 Tree St\n",
      "Paul Smith, 2000, 60 Spring St\n",
      "Sarah McDonald, 2001, 101 MLK Blvd\n"
     ]
    }
   ],
   "source": [
    "for line in open('students.txt'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we want to break up each line by commas. To do this, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane Doe', ' 2000', ' 101 Main St']\n",
      "['John Doe', ' 2001', ' 123 Oak St']\n",
      "['Ann Ko', ' 1999', ' 57 Tree St']\n",
      "['Paul Smith', ' 2000', ' 60 Spring St']\n",
      "['Sarah McDonald', ' 2001', ' 101 MLK Blvd']\n"
     ]
    }
   ],
   "source": [
    "for line in open('students.txt'):\n",
    "    words = line.strip().split(',')\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then keep separate name, birth year, and address lists by typing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane Doe', 'John Doe', 'Ann Ko', 'Paul Smith', 'Sarah McDonald']\n",
      "[' 2000', ' 2001', ' 1999', ' 2000', ' 2001']\n",
      "[' 101 Main St', ' 123 Oak St', ' 57 Tree St', ' 60 Spring St', ' 101 MLK Blvd']\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "birth_year_list = []\n",
    "address_list = []\n",
    "for line in open('students.txt'):\n",
    "    words = line.strip().split(',')\n",
    "    name_list.append(words[0])\n",
    "    birth_year_list.append(words[1])\n",
    "    address_list.append(words[2])\n",
    "print(name_list)\n",
    "print(birth_year_list)\n",
    "print(address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching through a file, we may only care about lines that being with certain strings. For example, consider this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: janedoe@gmail.com Sat Jan 5 2008\n",
      "To: jackdoe@aol.com\n",
      "Subject: Saturday Party\n",
      "\n",
      "From: annesmith@gmail.com Sun Jan 6 2008\n",
      "To: bobpaul@amazon.com\n",
      "Subject: I’m mad at you\n",
      "\n",
      "From: jackmac@mac.com Mon Jan 7 2008\n",
      "To: catdancy@gmail.com\n",
      "Subject: Not safe for work\n",
      "\n",
      "From: paullauren@gmail.com Tues Jan 9 2008\n",
      "To: mikejoy@aol.com\n",
      "Subject: For sale\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we only wanted to save the email addresses of the people who sent the emails (in the From: lines). We could use the command .startswith():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: janedoe@gmail.com Sat Jan 5 2008\n",
      "\n",
      "From: annesmith@gmail.com Sun Jan 6 2008\n",
      "\n",
      "From: jackmac@mac.com Mon Jan 7 2008\n",
      "\n",
      "From: paullauren@gmail.com Tues Jan 9 2008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we could save those emails by breaking up each line into words and saving the second word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['janedoe@gmail.com', 'annesmith@gmail.com', 'jackmac@mac.com', 'paullauren@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        words = line.split()\n",
    "        names.append(words[1])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['janedoe@gmail.com', 'annesmith@gmail.com', 'jackmac@mac.com', 'paullauren@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        names.append(line.split()[1])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you only wanted to save the username part of the email addresses to the right of the @ sign. You could use a delimiter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janedoe\n",
      "annesmith\n",
      "jackmac\n",
      "paullauren\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        words = line.split()[1].split('@')\n",
    "        print(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janedoe\n",
      "annesmith\n",
      "jackmac\n",
      "paullauren\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        print(line.split()[1].split('@')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - sports\n",
    "Open the file sports.txt. Break up each line by the delimiter \"-\". Then print a list of what each student plays in the spring. For example, each line should say something like \"Brenda plays track in the spring.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert sports code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - sports again\n",
    "In the sports file, break up each line by the delimiter \"-\". Then, use another delimiter to get the sports unattached from the seasons. Print a count of how many students are enrolled in each sport. For example, print something like \"Two students play track.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert sports again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football\n",
    "Break up the football.txt data using comma delimiters. Store the team names in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football 2\n",
    "Store the football.txt data as a list of lists for the different team data. Then, print the that has the minimum absolute value difference between their goals and goals allowed. (Hint: the answer should be Aston Villa.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Files\n",
    "---\n",
    "<a class=\"anchor\" id=\"csv\"></a>\n",
    "The so-called CSV (Comma Separated Values) format is the most common import and export format for spreadsheets and databases. For example, you can always store an Excel or Google sheet in CSV format. We can read them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', ' degree', ' title', ' email']\n",
      "['Scarlett L. Bellamy', ' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']\n",
      "['Warren B. Bilker', 'Ph.D.', 'Professor of Biostatistics', 'warren@upenn.edu']\n",
      "['Matthew W Bryan', ' PhD', 'Assistant Professor of Biostatistics', 'bryanma@upenn.edu']\n",
      "['Jinbo Chen', ' Ph.D.', 'Associate Professor of Biostatistics', 'jinboche@upenn.edu']\n",
      "['Susan S Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'sellenbe@upenn.edu']\n",
      "['Jonas H. Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'jellenbe@mail.med.upenn.edu']\n",
      "['Rui Feng', ' Ph.D', 'Assistant Professor of Biostatistics', 'ruifeng@upenn.edu']\n",
      "['Benjamin C. French', ' PhD', 'Associate Professor of Biostatistics', 'bcfrench@mail.med.upenn.edu']\n",
      "['Phyllis A. Gimotty', ' Ph.D', 'Professor of Biostatistics', 'pgimotty@upenn.edu']\n",
      "['Wensheng Guo', ' Ph.D', 'Professor of Biostatistics', 'wguo@mail.med.upenn.edu']\n",
      "['Yenchih Hsu', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hsu9@mail.med.upenn.edu']\n",
      "['Rebecca A Hubbard', ' PhD', 'Associate Professor of Biostatistics', 'rhubb@mail.med.upenn.edu']\n",
      "['Wei-Ting Hwang', ' Ph.D.', 'Associate Professor of Biostatistics', 'whwang@mail.med.upenn.edu']\n",
      "['Marshall M. Joffe', ' MD MPH Ph.D', 'Professor of Biostatistics', 'mjoffe@mail.med.upenn.edu']\n",
      "['J. Richard Landis', ' B.S.Ed. M.S. Ph.D.', 'Professor of Biostatistics', 'jrlandis@mail.med.upenn.edu']\n",
      "['Yimei Li', ' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu']\n",
      "['Mingyao Li', ' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu']\n",
      "['Hongzhe Li', ' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']\n",
      "['A. Russell Localio', ' JD MA MPH MS PhD', 'Associate Professor of Biostatistics', 'rlocalio@upenn.edu']\n",
      "['Nandita Mitra', ' Ph.D.', 'Associate Professor of Biostatistics', 'nanditam@mail.med.upenn.edu']\n",
      "['Knashawn H. Morales', ' Sc.D.', 'Associate Professor of Biostatistics', 'knashawn@mail.med.upenn.edu']\n",
      "['Kathleen Joy Propert', ' Sc.D.', 'Professor of Biostatistics', 'propert@mail.med.upenn.edu']\n",
      "['Mary E. Putt', ' PhD ScD', 'Professor of Biostatistics', 'mputt@mail.med.upenn.edu']\n",
      "['Sarah Jane Ratcliffe', ' Ph.D.', 'Associate Professor of Biostatistics', 'sratclif@upenn.edu']\n",
      "['Michelle Elana Ross', ' PhD', 'Assistant Professor is Biostatistics', 'michross@upenn.edu']\n",
      "['Jason A. Roy', ' Ph.D.', 'Associate Professor of Biostatistics', 'jaroy@mail.med.upenn.edu']\n",
      "['Mary D. Sammel', ' Sc.D.', 'Professor of Biostatistics', 'msammel@cceb.med.upenn.edu']\n",
      "['Pamela Ann Shaw', ' PhD', 'Assistant Professor of Biostatistics', 'shawp@upenn.edu']\n",
      "['Russell Takeshi Shinohara', '0', 'Assistant Professor of Biostatistics', 'rshi@mail.med.upenn.edu']\n",
      "['Haochang Shou', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hshou@mail.med.upenn.edu']\n",
      "['Justine Shults', ' Ph.D.', 'Professor of Biostatistics', 'jshults@mail.med.upenn.edu']\n",
      "['Alisa Jane Stephens', ' Ph.D.', 'Assistant Professor of Biostatistics', 'alisaste@mail.med.upenn.edu']\n",
      "['Andrea Beth Troxel', ' ScD', 'Professor of Biostatistics', 'atroxel@mail.med.upenn.edu']\n",
      "['Rui Xiao', ' PhD', 'Assistant Professor of Biostatistics', 'rxiao@mail.med.upenn.edu']\n",
      "['Sharon Xiangwen Xie', ' Ph.D.', 'Associate Professor of Biostatistics', 'sxie@mail.med.upenn.edu']\n",
      "['Dawei Xie', ' PhD', 'Assistant Professor of Biostatistics', 'dxie@upenn.edu']\n",
      "['Wei (Peter) Yang', ' Ph.D.', 'Assistant Professor of Biostatistics', 'weiyang@mail.med.upenn.edu']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "degree=[]\n",
    "\n",
    "with open('faculty.csv') as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    for row in data:\n",
    "        print(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first row is a header. If you wanted to skip it, you could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Scarlett L. Bellamy', ' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']\n",
      "['Warren B. Bilker', 'Ph.D.', 'Professor of Biostatistics', 'warren@upenn.edu']\n",
      "['Matthew W Bryan', ' PhD', 'Assistant Professor of Biostatistics', 'bryanma@upenn.edu']\n",
      "['Jinbo Chen', ' Ph.D.', 'Associate Professor of Biostatistics', 'jinboche@upenn.edu']\n",
      "['Susan S Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'sellenbe@upenn.edu']\n",
      "['Jonas H. Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'jellenbe@mail.med.upenn.edu']\n",
      "['Rui Feng', ' Ph.D', 'Assistant Professor of Biostatistics', 'ruifeng@upenn.edu']\n",
      "['Benjamin C. French', ' PhD', 'Associate Professor of Biostatistics', 'bcfrench@mail.med.upenn.edu']\n",
      "['Phyllis A. Gimotty', ' Ph.D', 'Professor of Biostatistics', 'pgimotty@upenn.edu']\n",
      "['Wensheng Guo', ' Ph.D', 'Professor of Biostatistics', 'wguo@mail.med.upenn.edu']\n",
      "['Yenchih Hsu', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hsu9@mail.med.upenn.edu']\n",
      "['Rebecca A Hubbard', ' PhD', 'Associate Professor of Biostatistics', 'rhubb@mail.med.upenn.edu']\n",
      "['Wei-Ting Hwang', ' Ph.D.', 'Associate Professor of Biostatistics', 'whwang@mail.med.upenn.edu']\n",
      "['Marshall M. Joffe', ' MD MPH Ph.D', 'Professor of Biostatistics', 'mjoffe@mail.med.upenn.edu']\n",
      "['J. Richard Landis', ' B.S.Ed. M.S. Ph.D.', 'Professor of Biostatistics', 'jrlandis@mail.med.upenn.edu']\n",
      "['Yimei Li', ' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu']\n",
      "['Mingyao Li', ' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu']\n",
      "['Hongzhe Li', ' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']\n",
      "['A. Russell Localio', ' JD MA MPH MS PhD', 'Associate Professor of Biostatistics', 'rlocalio@upenn.edu']\n",
      "['Nandita Mitra', ' Ph.D.', 'Associate Professor of Biostatistics', 'nanditam@mail.med.upenn.edu']\n",
      "['Knashawn H. Morales', ' Sc.D.', 'Associate Professor of Biostatistics', 'knashawn@mail.med.upenn.edu']\n",
      "['Kathleen Joy Propert', ' Sc.D.', 'Professor of Biostatistics', 'propert@mail.med.upenn.edu']\n",
      "['Mary E. Putt', ' PhD ScD', 'Professor of Biostatistics', 'mputt@mail.med.upenn.edu']\n",
      "['Sarah Jane Ratcliffe', ' Ph.D.', 'Associate Professor of Biostatistics', 'sratclif@upenn.edu']\n",
      "['Michelle Elana Ross', ' PhD', 'Assistant Professor is Biostatistics', 'michross@upenn.edu']\n",
      "['Jason A. Roy', ' Ph.D.', 'Associate Professor of Biostatistics', 'jaroy@mail.med.upenn.edu']\n",
      "['Mary D. Sammel', ' Sc.D.', 'Professor of Biostatistics', 'msammel@cceb.med.upenn.edu']\n",
      "['Pamela Ann Shaw', ' PhD', 'Assistant Professor of Biostatistics', 'shawp@upenn.edu']\n",
      "['Russell Takeshi Shinohara', '0', 'Assistant Professor of Biostatistics', 'rshi@mail.med.upenn.edu']\n",
      "['Haochang Shou', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hshou@mail.med.upenn.edu']\n",
      "['Justine Shults', ' Ph.D.', 'Professor of Biostatistics', 'jshults@mail.med.upenn.edu']\n",
      "['Alisa Jane Stephens', ' Ph.D.', 'Assistant Professor of Biostatistics', 'alisaste@mail.med.upenn.edu']\n",
      "['Andrea Beth Troxel', ' ScD', 'Professor of Biostatistics', 'atroxel@mail.med.upenn.edu']\n",
      "['Rui Xiao', ' PhD', 'Assistant Professor of Biostatistics', 'rxiao@mail.med.upenn.edu']\n",
      "['Sharon Xiangwen Xie', ' Ph.D.', 'Associate Professor of Biostatistics', 'sxie@mail.med.upenn.edu']\n",
      "['Dawei Xie', ' PhD', 'Assistant Professor of Biostatistics', 'dxie@upenn.edu']\n",
      "['Wei (Peter) Yang', ' Ph.D.', 'Assistant Professor of Biostatistics', 'weiyang@mail.med.upenn.edu']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "degree=[]\n",
    "\n",
    "with open('faculty.csv') as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    next(data, None)\n",
    "    for row in data:\n",
    "        print(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to write to a csv file, we could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = ['janedoe@gmail.com', 'jackdoe@amazon.com', 'sallysmith@aol.com']        \n",
    "with open('emails.csv', 'w', newline='') as csvfile:\n",
    "    myfile = csv.writer(csvfile)\n",
    "    myfile.writerow(['list_of_emails'])\n",
    "    for email in emails:\n",
    "            myfile.writerow([email])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we needed to put each string that we wanted to write to the csv file inside brackets. Otherwise, it would create a space between each letter in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Degrees\n",
    "\n",
    "Write a program that reads in faculty.csv and creates a dictionary of each degree (standardized to not include periods) and the count of each title. Your program should print: {'0': 1, 'PhD': 31, 'MPH': 2, 'ScD': 6, 'MS': 2, 'BSEd': 1, 'MA': 1, 'MD': 1, 'JD': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Title\n",
    "Write a program that reads in faculty.csv and creates a dictionary of each title and count (be careful to first account for a typo in the csv file. Your program should print: {'Professor of Biostatistics': 13, 'Assistant Professor of Biostatistics': 12, 'Associate Professor of Biostatistics': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - email\n",
    "Write a program that reads in faculty.csv and creates a unique list of the domain names (after the \"@\" symbol in the email address). Your program should print: {'cceb.med.upenn.edu', 'email.chop.edu', 'upenn.edu', 'mail.med.upenn.edu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - last name\n",
    "Write a program that reads in faculty.csv and creates a dictionary such that they key is the last name and the value is a list of the degree, title, and email. Be careful to account for duplicate last names. For example:\n",
    "\n",
    "'Bellamy': [[' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']]\n",
    "\n",
    "and\n",
    "\n",
    "'Li': [[' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu'], [' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu'], [' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert last name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - tuple\n",
    "Write a program that reads in faculty.csv and creates a dictionary such that the key is a tuple of the name and the value is the list of the degree, title, and email. You can assume each tuple name is unique. For example:\n",
    "\n",
    "('Benjamin', 'C.', 'French'): [' PhD',\n",
    "  'Associate Professor of Biostatistics',\n",
    "  'bcfrench@mail.med.upenn.edu']\n",
    "  \n",
    "  \n",
    " ('Dawei', 'Xie'): [' PhD',\n",
    "  'Assistant Professor of Biostatistics',\n",
    "  'dxie@upenn.edu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - write names\n",
    "Write a program that reads in faculty.csv and writes the names of the professors to a list called names.csv. You should include a header in the file such that the first line says \"Professor Names\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert write names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files in Other Locations\n",
    "---\n",
    "<a class=\"anchor\" id=\"locations\"></a>\n",
    "\n",
    "We have been reading files that are located in the directory of this program. If we needed to search somewhere else for the file, we would need to add a bit more to our file path name. \n",
    "\n",
    "On a Mac, if your username was janedoe and you wanted to print a \"hello.txt\" file located in your Documents folder, you would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in open('/Users/janedoe/Documents/hello.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a PC, you would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in open('C:/Users/janedoe/Documents/hello.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, neither of these will work, since we don't have a file called \"hello.txt\" located there.\n",
    "\n",
    "In fact, we'll learn better ways of referencing file path names when we learn about the os package in later units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Output\n",
    "---\n",
    "<a class=\"anchor\" id=\"output\"></a>\n",
    "\n",
    "To write a file, you have to open it with mode 'w' as a second parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='output.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "print(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file already exists, opening it in write mode clears out the old data and starts fresh, so be careful! If the file doesn’t exist, a new one is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write method of the file handle object puts data into the file. The file object keeps track of where it is, so if you call write again, it adds the new data to the end.\n",
    "\n",
    "When you are done writing, you have to close the file to make sure that the last bit of data is physically written to the disk so it will not be lost if the power goes off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "line1 = \"Oh, when it all, it all falls down,\\n\"\n",
    "fout.write(line1)\n",
    "\n",
    "line2 = \"I'm telling you, oh, it all falls down,\\n\"\n",
    "fout.write(line2)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above code that we had to add new line characters. The print statement automatically appends a newline, but the write method does not add the newline automatically. If you want each sentence to be on a different line, you'll need to add a \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that we actually wrote to that file, we can open it and read it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down,\n",
      "\n",
      "I'm telling you, oh, it all falls down,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('output.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to clear that file and rewrite the numbers between 1 and 10, we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "for i in range(1,11):\n",
    "    fout.write('Number:'+str(i)+'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's check our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:1\n",
      "\n",
      "Number:2\n",
      "\n",
      "Number:3\n",
      "\n",
      "Number:4\n",
      "\n",
      "Number:5\n",
      "\n",
      "Number:6\n",
      "\n",
      "Number:7\n",
      "\n",
      "Number:8\n",
      "\n",
      "Number:9\n",
      "\n",
      "Number:10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('output.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we needed to use plus signs instead of commas. Write does not accept commas between words like print does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() takes exactly one argument (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-8b0a56fa5e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() takes exactly one argument (3 given)"
     ]
    }
   ],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "for i in range(1,11):\n",
    "    fout.write('Number:',str(i),'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to ask the user for a file. If that file already exists, we want to add the user's words to the file. If the file doesn't exist, we want to create a new one. We would need to import the os package if using a Mac. We'll get more into importing packages later. For now, let's just use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What file do you want to add words to? journal.txt\n",
      "What do you want to say? Hi! This is my second one.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = input('What file do you want to add words to? ')\n",
    "say = input('What do you want to say? ')\n",
    "data = []\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(say+'\\n')    \n",
    "else:\n",
    "    f = open(filename, 'w')\n",
    "    f.write(say+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted to find the full path name of the file? You would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What file are you looking for? journal.txt\n",
      "/Users/shareshianl/Documents/CS/Python_Lessons/journal.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = input('What file are you looking for? ')\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print(os.path.abspath(filename))\n",
    "else:\n",
    "    print('That file does not exist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - multiples\n",
    "Write a program that stores the first 100 multiples of 7, each on a different line, in a file called 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - kanye\n",
    "Write a program that calculates Kanye's most used words in kanye.txt and prints them to a file, in decending order of frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert kanye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - calendar app\n",
    "Write a program that takes in a date in the form \"MM-DD-YY' and a reminder for that day. For example, a user might input \"09-27-17\" and \"Get Lauren a Birthday Present.\" The program should add this information to the file calendar.txt each time the user calls the program. One caveat: if the user enters a date that is already in the file, then that reminder should be inserted in the right spot, rather than at the end of the file. For example, two reminders for the date \"09-27-17\" should be next to each other. You don't need to worry about putting all of the dates in chronological order just yet. We'll do that in another program later when we get to the datetime module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert calendar app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
